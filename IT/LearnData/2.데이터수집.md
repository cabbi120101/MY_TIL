# 2. 데이터 수집 및 준비

데이터 수집 및 준비는 데이터 분석의 첫 단계로, 고품질의 데이터를 확보하고 분석할 수 있는 상태로 가공하는 과정을 포함합니다. 이 단계는 분석의 성공 여부를 좌우할 수 있기 때문에 매우 중요합니다.

## 2.1 데이터 수집

데이터 수집은 분석을 위해 필요한 데이터를 모으는 단계로, 다양한 출처에서 데이터를 가져오는 작업을 포함합니다.

### 2.1.1 데이터 수집 방법

- **웹 스크래핑 (Web Scraping):** 웹사이트의 데이터를 자동으로 추출하는 방법입니다. Beautiful Soup, Scrapy 같은 파이썬 라이브러리를 사용합니다.
- **API 사용:** 외부 서비스에서 데이터를 제공하는 API를 활용하여 데이터를 가져옵니다. 예를 들어, Twitter API를 사용하여 트위터 데이터를 수집할 수 있습니다.
- **데이터베이스 쿼리:** SQL을 사용하여 관계형 데이터베이스에서 데이터를 가져옵니다.
- **엑셀 및 CSV 파일:** 기존에 수집된 데이터 파일을 불러옵니다.
- **센서 및 IoT 데이터:** 사물인터넷 기기에서 실시간 데이터를 수집합니다.

### 2.1.2 데이터 유형

- **정형 데이터 (Structured Data):** 테이블 형식의 데이터로, 행과 열이 명확하게 정의된 데이터입니다. (예: Excel, SQL 데이터)
- **비정형 데이터 (Unstructured Data):** 텍스트, 이미지, 비디오 등의 형식을 포함한 구조화되지 않은 데이터입니다.
- **반정형 데이터 (Semi-structured Data):** JSON, XML 등 특정 구조를 가지고 있지만, 테이블 형식은 아닌 데이터입니다.

## 2.2 데이터 품질 관리

데이터 품질은 분석 결과의 신뢰성을 높이기 위해 매우 중요합니다. 이를 위해 데이터가 정확하고 일관되며 최신 상태인지를 검토해야 합니다.

### 2.2.1 데이터 품질의 요소

- **정확성 (Accuracy):** 데이터가 실제를 얼마나 잘 반영하는지 여부
- **일관성 (Consistency):** 데이터 간의 일관된 형식과 규칙성
- **완전성 (Completeness):** 필요한 데이터가 누락되지 않고 모두 포함되어 있는지
- **신뢰성 (Reliability):** 데이터 출처의 신뢰도와 데이터의 진실성

## 2.3 데이터 전처리 (Data Preprocessing)

데이터 전처리는 수집된 데이터를 분석에 적합하게 변환하는 과정입니다. 이 단계에서는 데이터 클렌징, 변환, 통합 등의 작업이 이루어집니다.

### 2.3.1 데이터 정제 (Data Cleaning)

- **결측치 처리 (Missing Values Handling):**
  - 제거 (Deletion): 결측값이 있는 행이나 열을 삭제
  - 대체 (Imputation): 평균, 중앙값, 모드 등을 사용하여 결측값을 대체
- **이상치 탐색 및 처리 (Outlier Detection and Handling):**
  - 이상치를 탐색하여 제거하거나, 변환하여 데이터의 왜곡을 최소화
- **중복 제거 (Duplicate Removal):** 중복된 데이터를 찾아 제거하여 데이터의 일관성을 유지

### 2.3.2 데이터 변환 (Data Transformation)

- **데이터 스케일링 (Scaling):** 데이터를 일정한 범위로 변환 (예: Min-Max 스케일링, 표준화)
- **데이터 인코딩 (Encoding):** 범주형 데이터를 수치형 데이터로 변환 (예: 원-핫 인코딩)
- **피처 엔지니어링 (Feature Engineering):** 새로운 변수를 만들어내어 분석의 정확성을 높임

### 2.3.3 데이터 통합 (Data Integration)

- 여러 출처에서 수집된 데이터를 통합하여 분석이 가능한 일관된 데이터 셋을 만듭니다.
- 데이터 통합 과정에서는 동일한 데이터를 반복적으로 사용하지 않도록 데이터 중복성을 제거합니다.

## 2.4 데이터 준비 도구 및 라이브러리

- **Python 라이브러리:**
  - Pandas: 데이터 처리 및 분석에 널리 사용되는 라이브러리
  - NumPy: 수치 데이터를 다루는 데 강력한 라이브러리
  - OpenPyXL, xlrd: Excel 데이터 처리용 라이브러리
- **SQL:** 데이터베이스 쿼리를 통해 데이터 수집 및 조작 가능
- **ETL 도구:** Talend, Apache Nifi 등 다양한 데이터를 수집하고 변환하는 데 도움을 주는 도구

## 2.5 데이터 준비의 중요성

- **정확한 분석 결과 보장:** 깨끗하고 일관된 데이터는 분석 결과의 정확성을 높입니다.
- **시간과 비용 절감:** 데이터 오류를 사전에 수정하여 이후 단계에서 발생할 문제를 줄입니다.
- **효과적인 의사결정 지원:** 품질 높은 데이터는 보다 나은 비즈니스 인사이트를 제공합니다.

---

이 단계에서 고품질의 데이터를 수집하고 준비하는 것이 이후의 데이터 분석과 시각화 작업의 성공을 좌우합니다. 다음으로 데이터 분석 도구와 언어를 익히면서 실전 분석 준비를 할 수 있습니다.
